{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "016f3f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/minkijung/Downloads/eagle_router/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet', 'val': 'data/val-00000-of-00001.parquet'}\n",
    "base = \"hf://datasets/notdiamond/repliqa_gpt4o_gpt4omini_evals/\"\n",
    "\n",
    "# Load full splits\n",
    "train_df_full = pd.read_parquet(base + splits[\"train\"])\n",
    "val_df_full = pd.read_parquet(base + splits[\"val\"])\n",
    "test_df_full = pd.read_parquet(base + splits[\"test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3ea9e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outcome\n",
      "Tie          7168\n",
      "Neither      1159\n",
      "Mini wins    1138\n",
      "4o wins       535\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your dataframe is called df\n",
    "mini = \"gpt-4o-mini-2024-07-18/score\"\n",
    "full = \"gpt-4o-2024-08-06/score\"\n",
    "\n",
    "\n",
    "def outcome(row):\n",
    "    if row[mini] == 1 and row[full] == 1:\n",
    "        return \"Tie\"\n",
    "    elif row[mini] == 1 and row[full] == 0:\n",
    "        return \"Mini wins\"\n",
    "    elif row[mini] == 0 and row[full] == 1:\n",
    "        return \"4o wins\"\n",
    "    else:\n",
    "        return \"Neither\"\n",
    "\n",
    "\n",
    "train_df_full[\"outcome\"] = train_df_full.apply(outcome, axis=1)\n",
    "\n",
    "# Get counts\n",
    "stats = train_df_full[\"outcome\"].value_counts()\n",
    "\n",
    "print(stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b1d53",
   "metadata": {},
   "source": [
    "More than 70% of the matches are tie. \n",
    "There are cases both model got 0 score, which I can't find what that means in the HF data info. \n",
    "\n",
    "To make the training more efficient, I'll sample train_df so there is no cases where both models got 0 scores, and make the tied cases 33%. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b07f65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outcome\n",
      "Mini wins    0.453567\n",
      "Tie          0.333200\n",
      "4o wins      0.213232\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Remove cases where both are 0 (\"Neither\")\n",
    "train_df_no_neither = train_df_full[train_df_full[\"outcome\"] != \"Neither\"]\n",
    "\n",
    "# Separate out tie vs non-tie cases\n",
    "tie_df = train_df_no_neither[train_df_no_neither[\"outcome\"] == \"Tie\"]\n",
    "non_tie_df = train_df_no_neither[train_df_no_neither[\"outcome\"] != \"Tie\"]\n",
    "\n",
    "# Compute how many tie rows to keep so ties are ~33% of the final set\n",
    "target_tie_count = int(\n",
    "    len(non_tie_df) * (1 / 2)\n",
    ")  # 1/2 because ties / (ties + non_ties) â‰ˆ 1/3\n",
    "\n",
    "# Sample ties\n",
    "tie_sampled = tie_df.sample(n=min(target_tie_count, len(tie_df)), random_state=42)\n",
    "\n",
    "# Combine into final training set\n",
    "train_df = pd.concat([non_tie_df, tie_sampled], ignore_index=True)\n",
    "\n",
    "# Check new distribution\n",
    "print(train_df[\"outcome\"].value_counts(normalize=True))\n",
    "\n",
    "# drop outcome column\n",
    "train_df = train_df.drop(columns=[\"outcome\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f512e39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample exactly 1000/100/100 rows (deterministic)\n",
    "df_train = train_df.sample(n=1000, random_state=42)\n",
    "df_val = val_df_full.sample(n=100, random_state=42)\n",
    "df_test = test_df_full.sample(n=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b3a3d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outcome\n",
      "Tie          7168\n",
      "Neither      1159\n",
      "Mini wins    1138\n",
      "4o wins       535\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your dataframe is called df\n",
    "mini = \"gpt-4o-mini-2024-07-18/score\"\n",
    "full = \"gpt-4o-2024-08-06/score\"\n",
    "\n",
    "\n",
    "def outcome(row):\n",
    "    if row[mini] == 1 and row[full] == 1:\n",
    "        return \"Tie\"\n",
    "    elif row[mini] == 1 and row[full] == 0:\n",
    "        return \"Mini wins\"\n",
    "    elif row[mini] == 0 and row[full] == 1:\n",
    "        return \"4o wins\"\n",
    "    else:\n",
    "        return \"Neither\"\n",
    "\n",
    "\n",
    "train_df_full[\"outcome\"] = train_df_full.apply(outcome, axis=1)\n",
    "\n",
    "# Get counts\n",
    "stats = train_df_full[\"outcome\"].value_counts()\n",
    "\n",
    "print(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3ae8f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outcome\n",
      "Mini wins    445\n",
      "Tie          338\n",
      "4o wins      217\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your dataframe is called df\n",
    "mini = \"gpt-4o-mini-2024-07-18/score\"\n",
    "full = \"gpt-4o-2024-08-06/score\"\n",
    "\n",
    "\n",
    "def outcome(row):\n",
    "    if row[mini] == 1 and row[full] == 1:\n",
    "        return \"Tie\"\n",
    "    elif row[mini] == 1 and row[full] == 0:\n",
    "        return \"Mini wins\"\n",
    "    elif row[mini] == 0 and row[full] == 1:\n",
    "        return \"4o wins\"\n",
    "    else:\n",
    "        return \"Neither\"\n",
    "\n",
    "\n",
    "df_train[\"outcome\"] = df_train.apply(outcome, axis=1)\n",
    "\n",
    "# Get counts\n",
    "stats = df_train[\"outcome\"].value_counts()\n",
    "\n",
    "print(stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc57caa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12043bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedd all prompts\n",
    "from openai import OpenAI\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19343426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate embeddings for prompts\n",
    "df_train[\"prompt_embedding\"] = df_train[\"prompt\"].apply(\n",
    "    lambda x: client.embeddings.create(input=x, model=\"text-embedding-3-large\")\n",
    "    .data[0]\n",
    "    .embedding\n",
    ")\n",
    "\n",
    "\n",
    "# save dataset with embeddings\n",
    "df_train.to_parquet(\"data/train_1000.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0e2b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate embeddings for prompts\n",
    "df_test[\"prompt_embedding\"] = df_test[\"prompt\"].apply(\n",
    "    lambda x: client.embeddings.create(input=x, model=\"text-embedding-3-large\")\n",
    "    .data[0]\n",
    "    .embedding\n",
    ")\n",
    "\n",
    "# save dataset with embeddings\n",
    "df_test.to_parquet(\"data/test_100.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a513529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate embeddings for prompts\n",
    "df_val[\"prompt_embedding\"] = df_val[\"prompt\"].apply(\n",
    "    lambda x: client.embeddings.create(input=x, model=\"text-embedding-3-large\")\n",
    "    .data[0]\n",
    "    .embedding\n",
    ")\n",
    "\n",
    "\n",
    "# save dataset with embeddings\n",
    "df_val.to_parquet(\"data/val_100.parquet\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
